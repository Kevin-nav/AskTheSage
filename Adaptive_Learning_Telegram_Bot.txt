Adaptive Learning Telegram Bot1. High-Level Vision & PurposeThe goal of this project is to create a highly effective and user-friendly Telegram bot that helps students master any subject through a personalized, adaptive learning system. The bot will use a hybrid spaced repetition algorithm and on-demand content rendering (including image and text generation) to deliver a dynamic and engaging learning experience. Our primary target users are high school and early college students studying various courses.2. Core Features & LogicUser Interaction & NavigationState-based Conversation: We will use the python-telegram-bot library's ConversationHandler to manage user sessions. This allows us to track the user's state (e.g., CHOOSE_PROGRAM, CHOOSE_LEVEL, IN_QUIZ) and respond appropriately.Inline Keyboards: All navigation and responses will be handled via inline keyboards. This provides a clean, responsive, and mobile-friendly interface, eliminating the need for users to type commands.Persistent User Data: User-specific information, such as their current program, difficulty level, and quiz state, will be stored in context.user_data, which is ideal for managing short-term session data.Hybrid Question Fetching & Adaptive LogicThe bot will use a hybrid algorithm to intelligently select questions, ensuring a personalized and effective learning experience. This system combines weakness-based prioritization, spaced repetition, and broad coverage.Weakness-based Prioritization: The system will identify and prioritize a user's weak areas. We will track the number of incorrect answers for each topic. The algorithm will maintain a dynamic "weakness score" for each topic, and questions from topics with the highest scores will be served more frequently. This ensures the user focuses on the material they need to master most.Spaced Repetition System (SRS): The bot will implement a spaced repetition algorithm, similar to the SuperMemo 2 (SM-2) model, to schedule reviews at increasing intervals. This system is based on three key data points for each question/topic:repetitions: The number of times the user has answered the question correctly in a row.interval: The number of days to wait before the next review.easiness_factor: A floating-point number that adjusts the interval. It starts at 2.5 and changes based on the user's performance.The logic works as follows:If the answer is correct:If repetitions is 0, set interval to 1 day.If repetitions is 1, set interval to 6 days.If repetitions is greater than 1, calculate interval = interval * easiness_factor.Increment repetitions by 1.Adjust the easiness_factor based on a quality rating of the response (e.g., a scale from 0 to 5, where 5 is a perfect response).If the answer is incorrect:Reset repetitions to 0.Reset interval to 1 day.The easiness_factor does not change.This dynamic system ensures that questions the user knows well are seen less often, while difficult questions are repeated more frequently.Broad Coverage: To prevent the user from getting stuck in a loop of a few difficult topics, the algorithm will also include a percentage of questions from other topics, ensuring comprehensive coverage of the course material over time.Data Points & User TrackingWe will track a comprehensive set of data points to inform the adaptive learning system and provide a rich understanding of user progress. This data will be stored in the PostgreSQL database.user_id: Unique identifier for each user.question_id: Unique identifier for each question.topic_id: The subject or topic the question belongs to.timestamp: The date and time of the user's response.result: A boolean value (true or false) indicating if the answer was correct.score: A numerical representation of the user's performance on a topic.repetitions: Tracks the number of consecutive correct answers for a question (for SRS).interval: The current review interval for a question (for SRS).easiness_factor: The easiness factor for a question (for SRS).session_id: To group related user interactions.learning_path: A record of the topics and questions a user has completed.On-Demand Content RenderingPurpose: To handle complex course content like mathematical equations, plots, diagrams, or even specific text formats that cannot be displayed directly in a Telegram message. We will render them as images.Backend Tooling: We will use Matplotlib to generate images from LaTeX code, and we can extend this to other libraries for general diagram or chart generation.Caching Strategy: To avoid redundant rendering and reduce server load, we will implement a two-tier caching system. An in-memory cache will store recently rendered images, and a file-based cache on Amazon S3 will store them for long-term use.Issue Reporting SystemUser Feedback: Users will have the option to report issues with a question (e.g., incorrect answer, typo, unclear phrasing).Database Logging: When a user reports an issue, the bot will log a timestamped record to the PostgreSQL database, including the user_id, the question_id, and the issue_type. This data is crucial for continuous improvement of our question bank.3. Architecture & ScalabilityThe project's architecture is designed for reliability, performance, and scalability.Two-Tier AWS InfrastructureOur setup will consist of two primary AWS components:Two Free-Tier AWS EC2 instances: These will run our Python application (the Telegram bot).AWS Relational Database Service (RDS) for PostgreSQL: This will host our database.Nginx Load Balancer & Reverse ProxyWe will set up Nginx on a dedicated EC2 instance to serve as both a load balancer and a reverse proxy. This is a critical component for ensuring high availability and efficient request distribution.Least Connection Algorithm: Nginx will use the least_conn load-balancing algorithm. This directs new requests to the backend server with the fewest active connections, preventing a single server from becoming a bottleneck.Failover Mechanism: The Nginx configuration will include health checks and a failover mechanism. If one of the backend EC2 instances becomes unhealthy, Nginx will automatically stop routing traffic to it and redirect all requests to the healthy instance, providing robust redundancy.Database ManagementPostgreSQL with AWS RDS: We will use a PostgreSQL database hosted on AWS RDS. A relational database is an excellent choice for this project because our data (users, questions, quiz logs) is highly structured. RDS provides a managed service, handling backups, patches, and scalability, allowing us to focus on development.Database Schema: The database will include tables for:users: Stores user information (e.g., telegram_id, state).questions: Contains the actual questions, topics, difficulty, and content.user_progress: Tracks user performance on each topic and question.issue_reports: Logs user-reported issues for future review.Amazon S3 for Content StorageInstead of storing content directly in the database, which is inefficient and costly, we will use Amazon S3 (Simple Storage Service). S3 is an object storage service built for high availability and scalability.Usage: Once a new image is rendered, it will be uploaded to a designated S3 bucket.Benefits: This approach offloads the storage burden from our database, reduces server processing, and provides a scalable solution for storing a potentially large number of rendered images and other content types.Performance & Reliability OptimizationsSwap Space: To prevent the OOM Killer (Out-of-Memory Killer) from terminating our application, we will set up swap space on our EC2 instances. This creates a dedicated portion of the hard drive that acts as temporary "virtual RAM," providing a buffer for memory-intensive operations, such as content rendering. This is a critical step for stability on free-tier instances with limited physical memory.In-Memory Question Queue: The bot will load a subset of questions into an in-memory queue at the beginning of each session. This reduces the number of database queries during a quiz, significantly speeding up the user experience.On-Demand Rendering: The choice to render content on demand rather than pre-rendering everything is a major performance decision. While caching helps, pre-rendering is not feasible for the massive number of unique content combinations possible with custom equations and other user inputs.